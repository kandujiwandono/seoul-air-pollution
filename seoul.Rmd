---
title: "Forecasting Seoul Air Polution using ARIMA Model"
author: "Kandu Jiwandono"
date: "14 April 2020"
output: 
  html_document:
    number_sections: true
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
    df_print: paged
    theme: united
    highlight: tango
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center")
```

# Introduction


The goal of this Rmd is to calculate and predict air pollution level of O~3~ and NO~2~ using ARIMA method at Seoul, South Korea. The datasets was obtained from [kaggle.com](https://www.kaggle.com/bappekim/air-pollution-in-seoul). Thanks to Seoul City, Seoul Open Data Plaza, and Air Quality Analysis Center for providing data.  
  
  
  
# Get Started
## Get Library loaded

first thing first, load several library to R. `readr` is required to importing the datasets into R.`tidyverse` is required to tidying the data. `tseries` is required to calculate the ARIMA model. `forecast` is required to make prediction. And also load `ggplot2` to do some data visualization.
```{r load_library}
library(readr)
library(tidyverse)
library(tseries)
library(forecast)
library(ggplot2)
```
  
  
  
## Import Datasets
Next, after we load all of the required R library, we load the Seoul Air Polution datasets into R by using `read_csv` command. We store the datasets into `df_seoul_air_pollution`
```{r import_datasets}
df_seoul_air_pollution <- read_csv("datasets/Measurement_summary.csv")
```

## Getting to know your data
The very first thing after we imported the data is to know our own datasets. To accomplish that simply just run `glimpse` from `dplyr` packages at R to inspect the datasets.
```{r inspect-datasets}
glimpse(df_seoul_air_pollution)
```
and also we can view 5 first entry and 5 last entry of the data to get a better look of it.
```{r head}
head(df_seoul_air_pollution)
tail(df_seoul_air_pollution)
```
From the results above, we can conclude that 11 columns and 647,511 rows. The columns does not only contain pollutant data but also contain measurement date, and station detail location (address, code, coordinate). The pollutant data consist of SO~2~, NO~2~, O~3~, CO, PM~10~, and PM~2.5~. We also knew that the data is an hourly average data of several polutant start from 2017-01-01 until 2019-12-31.  
We can also see the summary of our data by running `summary` and we also check total missing data from each row.
```{r summary}
summary(df_seoul_air_pollution)

# Checking missing data
colSums(is.na(df_seoul_air_pollution))
```
the results shows that the datasets does not contain any missing data. it means we don't have to do some missing data imputation to the data. Unfortunately we have an incorrect data. There is no way that an concentration value is negative so we are going to fix this data and replace it with other data.
  
  
  
  
# Data Cleaning
## Identifying the problem
Before conducting the data cleaning process, we need to know why the data needs to clean up. As mention before, the default datasets does not contain a single missing data. Is it true? if we take a look again at the summary of the datasets, we know that there are a negative number in all pollutant concentration. Negative number in concentration are not valid. So, either we change the number with other number such as, mean, median, etc Or we can simply change them into `NA` or missing value.  
Second, there are several location prior to the data. it means the pollutant data contain several number of station. in this analysis we only use just 1 station which is **`Station Code` 104**.  
Third, the goal of this RMD is to make a time series model and prediction of O~3~ and NO~2~. So we have to filter out other variable that we dont need. We only need  `O3`, `NO2` and `Measurement Date` data from the datasets and also maybe renaming the `Measurement Date` column so it does contain any space character in its name.  
Fourth, another problem in this data sets is skipped measurement date. It means that several dates or hour had been skipped for unknown reason. for example, let's take a look at the datasets from **2019-03-11** to **2019-03-20**
```{r checking_skipped_date}
df_seoul_air_pollution %>% 
  filter(`Measurement date`<= as.Date("2019-03-20"), `Measurement date` >= as.Date("2019-03-11"),
         `Station code` == 104)
```
From the table above we can see that at 11 March 2019 the data only available from 05.00 to 09.00, and there are no data inputed 12 March 2019 to 17 March 2019.
Let's solve the problem from the easier one first.

## Selecting Parameters and station
The goal of this RMD is to forecast O~3~ and NO~2~ concentration in the future using ARIMA Method therefore, we select only the required columns (which are O~3~, NO~2~, and Measurement date) to make our dataframe clean and tidy. We dont really need any of station detail such as coordinate, address, code, etc because we want to make a time series model.
```{r select_columns}
# check the unique value of station code
df_seoul_air_pollution %>% 
  distinct(`Station code`)

# filtering station code and selecting parameters
df_o3_no2 <- df_seoul_air_pollution %>% 
  filter(`Station code` == 104) %>% 
  select(`Measurement date`, NO2, O3)
```
we store the filtered columns to `df_o3_no2`

## Renaming Columns
Lets check the columns name on `df_o3_no2` by running `names` in R
```{r col_names}
# checking names of columns
names(df_o3_no2)
  
```
So, the data consists of 3 columns just as we selected before, and the name of the columns is measurement date, NO2, and O3. We change the columns name to make it easier to spell. Change the measurement date column into date column by running `rename` in R and store it again into `df_o3_no2`
```{r rename_col}
#renaming columns
df_o3_no2 <- df_o3_no2 %>% 
  rename(Date = `Measurement date`)

#check if the column name already changed
names(df_o3_no2)
```
## Filling out skipped date
As mentioned before, skipped date occurs several times in datasets. The skipped date must be filled, in this case the value will be NA. Filling skipped date data could be done by making a new datasets containing a full series of date, filter it out by the original datet data, and then merged 2 data sets into 1.
```{r filling_skipped_date}
# creating a new datasets contain full date from 2017-01-01 to 2019-12-31
df_full_date <- data.frame(Date = seq(as.POSIXct("2017-01-01 00:00:00"), as.POSIXct("2019-12-31 23:00:00"), by= "hour"),
                           NO2 = NA, O3 = NA)

# filtering the date
df_full_date <- df_full_date %>% 
  filter(!Date %in% df_o3_no2$Date)

# join 2 datasets into a new df
df_o3_no2 <- df_full_date %>% 
  full_join(df_o3_no2) %>% 
  filter(Date >= as.Date("2017-01-01")) %>% 
  arrange(Date)

# crosscheck if the jobs done
df_o3_no2 %>% 
  filter(Date >= as.Date("2019-03-11"), Date <= as.Date("2019-03-20"))
```
**JOBS DONE!!**

## Replacing negative value
as we all know, the concentration value of a pollutant is not a negative number. there are several observation which has negative number, so either we replace it with any other number or we just simply drop the observation value. First, lets take a look at the negative number on the data, and then replace it with `NA`
```{r replacing_neg_value, results= 'hide'}
# splitting datasets into two
df_no2 <- df_o3_no2 %>% 
  select(Date, NO2)

df_o3 <- df_o3_no2 %>% 
  select(Date, O3)

# filtering negative data
## NO2
df_no2 %>% 
  filter(NO2 < 0)

## O3
df_o3 %>% 
  filter(O3 < 0)

## Both of O3 and NO2
df_o3_no2 %>% 
  filter(O3<0, NO2 <0)

# replacing negative number with NA
## NO2
df_no2 <- df_no2  %>%  
  mutate(Date = as.Date(Date, format = "%Y-%m-%d"),
         NO2 = replace(NO2, which(NO2<0), NA))

## O3
df_o3 <- df_o3 %>% 
  mutate(Date = as.Date(Date, format = "%Y-%m-%d"),
         O3 = replace(O3, which(O3<0), NA))

```
The replacing process should be done by now, and now we have missing value to take care.


## Reshaping Data
Before we go into further analysis, we must reshape the data and make the data as tidy as possible. First, what we need is a daily average data not an hourly average data, so we calculate the daily average data by averaging 24 hour data for NO~2~. Second, what we need for O~3~ is 8 hour average daily data from 08.00 to 16.00. It is because O~3~ is formed by fotochemical reaction with the help of sun light. So, we need to calculate a new data for both of pollutant.  

### NO~2~
The calculation is not a simple 24 average. First, we need to check if the total available data of the day are 80% or more. if the data is sufficient then we can count the mean by ignoring the missing data. if the data availability below 80% we should drop the data and replace it with `NA`.  

```{r reshape_data_no2}

#24 hour average for no2

i = 1
df_ins = df_no2
inscol = 2
mulai = 1
akhir = 24
jml_data = 24
n80 = as.integer(0.8*jml_data)
N = nrow(df_ins)
nhari= N/jml_data
df_no2_baru <- data.frame(Date = seq(as.Date("2017-01-01", format = "%Y-%m-%d"), as.Date("2019-12-31", format = "%Y-%m-%d"), by = "day"), NO2 =1) 

for(i in 1:nhari){
  if(sum(!is.na(df_ins[mulai:akhir,inscol]))>=n80){ 
    df_no2_baru[i,2]<-colMeans(as.data.frame(df_ins[mulai:akhir,inscol]),na.rm = TRUE)
  }
  else {df_no2_baru[i,2]=NA}
  
  mulai<-mulai+jml_data
  akhir<-akhir+jml_data
}

## checking number of NA
df_no2_baru %>% filter(is.na(NO2))

rm(i, df_ins, inscol, mulai, akhir, jml_data, n80, N, nhari)
```
Store the calculation result as `df_no2_baru`  
  
  
### O~3~
Like NO~2~, The calculation for reshaping O~3~ data is not a simple 8 hours mean. At first, the data will be filtered only from 08.00 to 16.00 per day. Second, check the availability of the data perday. If the data availability more than 80% then calculate the mean, else we drop the data and replace it with `NA`.
```{r reshape_data_o3}
# Daily 8 hours average for O3
i = 1
df_ins = df_o3
inscol = 2
mulai = 8
akhir = 16
jml_data = 24
n80 = as.integer(0.8*9)
N = nrow(df_ins)
nhari= N/jml_data
df_o3_baru <- data.frame(Date = seq(as.Date("2017-01-01", format = "%Y-%m-%d"), as.Date("2019-12-31", format = "%Y-%m-%d"), by = "day"), O3 =1) 

for(i in 1:nhari){
  if(sum(!is.na(df_ins[mulai:akhir,inscol]))>=n80){ 
    df_o3_baru[i,2]<-colMeans(as.data.frame(df_ins[mulai:akhir,inscol]),na.rm = TRUE)
  }
  else {df_o3_baru[i,2]=NA}
  
  mulai<-mulai+jml_data
  akhir<-akhir+jml_data
}

## checking number of NA
df_o3_baru %>% filter(is.na(O3))

rm(i, df_ins, inscol, mulai, akhir, jml_data, n80, N, nhari)
```
Store the calculation result as `df_o3_baru`  

## Imputing missing value
We need imputing missing value because if we dont impute it we cannot calculate the time series model. The imputation method is interpolation. Interpolation is a type of estimation, a method of constructing new data points within the range of a discrete set of known data points. For the time series type data, we just have to run a function called `tsclean` from `forecast` packages to help us clean the  data.

```{r cleaning_data}
# Clean NO2
df_no2_baru$NO2 <-  tsclean(df_no2_baru$NO2)

# Clean O3
df_o3_baru$O3 <- tsclean(df_o3_baru$O3)
```

  
# Fitting ARIMA Model
## Examine your data
A good starting point to making a model is to take a look at your data. Even we already have the data being cleaned, it does not hurt us to take a look again at the data in order to check the data compability to the model.
```{r Examine_data, echo=F}
# Examine Plot NO2
df_no2_baru %>% 
  ggplot(aes(x = Date, y= NO2))+
  geom_line()+
  labs(title = "NO2 in SEOUL",
       subtitle = "From 2017 to 2019")+
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# Examine plot O3
df_o3_baru %>% 
  ggplot(aes(x = Date, y= O3))+
  geom_line()+
  labs(title = "O3 in SEOUL",
       subtitle = "From 2017 to 2019")+
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

From the graphic above, looks like both of the data has seasonality effect. The concentration of NO~2~ rises at the end of the year and decline at the middle of the year. On the contrary, the concentration of O~3~ rises at the middle of the year and decline at the the end of the year. In Korea, the end of the year means winter and the middle of the year means summer. So we can conclude that O~3~ Concentration will increase at Summer but decline at Winter, and NO~2~ concentration wikll increase at Winter but decline at Summer.  
  
  
## Decompose the Data  
The building block of time series data is seasonality, trend, and cycle. In order to find that, we can decompose the data using `decompose` function in `tseries` packages in R. Decomposing the data aims to detect the data behaviour wether seasonality, trend, and cycle are exist or not.
```{r decompose_no2, echo = F}
# Decomposing NO2
df_no2_ts <- ts(df_no2_baru$NO2, frequency = 365, start = c(2017, 1))
no2_stl <- stl(df_no2_ts, s.window = "periodic")
plot(no2_stl, main = "NO2 Decompose")
```
From 4 set of graphs above, we can conclude that, there are seasonal effect in the data and also for there are no significant trend for NO2 concentration data. This information obtained from gray bar at right side of the plot. The grey bar at the seasonal section is a little bigger than at the data section. It indicates that the data has seasonal effect on it.

```{r, decompose_o3, echo=FALSE}
# Decomposing O3
df_o3_ts <- ts(df_o3_baru$O3, frequency = 365, start = c(2017, 1))
o3_stl <- stl(df_o3_ts, s.window = "periodic")
plot(o3_stl, main = "O3 Decompose")
```

Again, from the 4 sets of graph above, we can conclude that, there are seasonal effect and no trend in O3 data.

## Dealing with seasonal component
From the graph before, we can conclude that both of NO~2~ and O~3~ has seasonality effect. From the graph above, the season period of these 2 pollutant approximately are 1 year or 365 days. Before we calculate the ARIMA model, we should remove the seasonality first. Removing seasonality can be done by running `seasadj()` in R.
```{r season_adj}
# Season_adj for NO2
df_no2_ts_adj <- seasadj(no2_stl)

# Season_adj for O3
df_o3_ts_adj <- seasadj(o3_stl)
```
Save the results into new variable called `df_no2_ts_adj` for NO~2~ and `df_o3_ts_adj` for O~3~.
The other alternative that we can approach is by using seasonal ARIMA model or called SARIMA. This model can handle seasonality that exist in the series so we don't have to adjust the series in order to eliminate the seasonal effect.

## Detecting Stationarity
Fitting an ARIMA model requires a stationary data. A series is said to be stationary when its mean, variance, and autocovariance are time invariant. This assumption makes intuitive sense: Since ARIMA uses previous lags of series to model its behavior, modeling stable series with consistent properties involves less uncertainty.  

The formal test to check wether a series is stationary is Augmented Dickey-Fuller (ADF). The null hypothesis assumes that the series is non stationary, The ADF test can be done in R by running `adf.test`
```{r adf_test, echo=FALSE}
# adf_test for NO2
adf.test(df_no2_ts)

# adf_test for O3
adf.test(df_o3_ts)
```

Both of O~3~ and NO~2~ adf-test results shows they have p-value of 0.01. From the adf-test result we can conclude that both of O~3~ and NO~2~ series are non stationary because both of them have **p-value < 0.05**  
  
  
  
## Fitting ARIMA Model  
Fitting ARIMA model or Seasonal ARIMA Model in R requires a packages called `forecast`.
The `forecast` packages allows user to determine their own order of ARIMA model by using `arima()` function or we can automatically select the order by its aic and bic number by running `auto.arima()` function. In this case, we try to fitting Seasonal ARIMA model by using `auto.arima` function but forcing the function to fit only Seasonal ARIMA.
```{r auto_arima, warning=TRUE}
# Fitting ARIMA model NO2
fit_no2 <- auto.arima(df_no2_ts,stepwise = F, test = "adf", seasonal = TRUE, D= 1,
                      seasonal.test = "ocsb")

# Fitting ARIMA model O3
fit_o3 <- auto.arima(df_o3_ts, stepwise = F, test = "adf", D=1, 
                     seasonal = TRUE, seasonal.test = "ocsb")

summary(fit_no2)
summary(fit_o3)

```
store the fitted Seasonal ARIMA model in a new variable called `fit_no2` for NO2 model, and `fit_o3` for O3 model.
After we fitted Seasonal ARIMA model for each pollutant now we can forecast both of pollutant concentration. Forecasting concentration from fitted model can be done by running `forecast()`.
```{r forecasting}
# Forecasting for NO2
no2_forecasted <- forecast(fit_no2, h = 365)

# Forecasting for O3
o3_forecasted <- forecast(fit_o3, h= 365)
```
Store the forecast results to a new variable called `no2_forecasted` and `o3_forecasted` for each pollutant. Take a look at first 30 days of forecasted concentration from both pollutant
```{r forecast_view}
# Creating data frame from first 30 days of forecasted data
forecasted <- data.frame(DATE = seq(as.Date("2020-01-01", format = "%Y-%m-%d"), as.Date("2020-01-30", format = "%Y-%m-%d"), by = "day"),
           no2_forecasted = no2_forecasted$mean[1:30],
           O3 = o3_forecasted$mean[1:30])
```
```{r preview_forecasted , echo=F}
forecasted
```

if we plot all of the forecasted results in 365 day, the graph would be 
```{r plot, echo = FALSE}
# Plot NO2
autoplot(no2_forecasted)+
  labs(title = "NO2 Forecast from ARIMA(4,0,1)(0,1,0)[365] with drift",
       y= "NO2 Concentration",
       x= "Date")+
  theme(plot.title = element_text(hjust = 0.5))

# Plot O3
autoplot(o3_forecasted)+
  labs(title = "O3 Forecast from ARIMA(3,0,1)(0,1,0)[365]",
       y= "NO2 Concentration",
       x= "Date")+
  theme(plot.title = element_text(hjust = 0.5))
```

## Model Accuracy
Last, ofcourse we want to know how well our model works. To find out how well our model works we can just model accuracy as a parameter to evaluate our fitted model.
```{r accuracy}
# NO2 model accuracy
accuracy(fit_no2)

# O3 model accuracy
accuracy(fit_o3)
```

From the results above, we can say that the average percentage error of the NO~2~ model is 26.75% and for O~3~ we cant really tell how much the error. This indicates that something wrong with the model. First we check the acf and pacf from model residuals
```{r}
acf(fit_no2$residuals)
pacf(fit_no2$residuals)

acf(fit_o3$residuals)
pacf(fit_o3$residuals)
```
The ACF and PACF plot for those 2 models seems awful. There are so many of black vertical lines crossing the blue striped line. It means that the model does not meet auto correlation assumption. The model error can also caused by ARIMA model itself since it cannot handle longer period of seasonality and multiple seasonality.  This problem can be solved by transforming daily data into weekly or maybe monthly data in order to shorten the period of seasonality.

